<!DOCTYPE html>
<html lang="en-us">
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-8534189-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-8534189-2');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>It’s the data, not the algorithm · Matt Sherman</title>
  <meta name="description" content="Chris Dixon points out that the challenge in “artificial intelligence” — which in a mainstream definition would be “making computers learn like humans” — is not so much the cleverness of the algorithm but in finding useful data.">
  <meta name="author" content="Matt Sherman">
  <link href="/css/style.css?3" rel="stylesheet">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <meta name="generator" content="Hugo 0.42.2">

  <link rel="alternate" type="application/atom+xml" href="/index.xml" title="clipperhouse.com">


<meta name="twitter:card" content="summary" />
<meta name="twitter:creator" content="@clipperhouse" />
<meta name="twitter:site" content="@clipperhouse" />
<meta property="og:url" content="https://clipperhouse.com/its-the-data-not-the-algorithm/" />
<meta name="twitter:title" content="It’s the data, not the algorithm · Matt Sherman" />
<meta property="og:title" content="It’s the data, not the algorithm · Matt Sherman" />
<meta name="twitter:description" content="Chris Dixon points out that the challenge in “artificial intelligence” — which in a mainstream definition would be “making computers learn like humans” — is not so much the cleverness of the algorithm but in finding useful data." />
<meta property="og:description" content="Chris Dixon points out that the challenge in “artificial intelligence” — which in a mainstream definition would be “making computers learn like humans” — is not so much the cleverness of the algorithm but in finding useful data." />
<meta name="twitter:image" content="https://clipperhouse.com/img/apple-touch-icon.png" />
<meta property="og:image" content="https://clipperhouse.com/img/apple-touch-icon.png" />
</head>
<body class="single ">
  <header class="header">
    
    <p class="title"><a href="/">clipperhouse.com</a></p>
    
    <button class="menu-toggle" type="button"></button>
    <nav class="menu">
      <ul>
        
        
        <li class="">
          <a href="/about/">about</a>
        </li>
        
      </ul>
    </nav>
  </header>

  <script type="text/javascript">
    function toggleMenu() {
        var menu = document.querySelector('nav.menu');
        menu.style.display = menu.style.display == "none" ? "block" : "none";
    }
    document.querySelector('button.menu-toggle').onclick = toggleMenu;
  </script>
  <main class="main">

<article class="post post-view">
  <header class="post-header">
  <h1 class="post-title"><a href="https://clipperhouse.com/its-the-data-not-the-algorithm/">It’s the data, not the algorithm</a></h1>
  <p class="post-meta">Published by Matt Sherman · August 30, 2009</p>
</header>
<div class="post-content">
  <p>Chris Dixon <a href="http://www.cdixon.org/?p=340">points out</a> that the challenge in “artificial intelligence” — which in a mainstream definition would be “making computers learn like humans” — is not so much the cleverness of the algorithm but in finding useful data. He cites the Google example where the breakthrough was realizing that links are a good (and previously untapped) source of data on what people think is a relevant web page.
Modern AI algorithms are very powerful, but the reality is there are thousands of programmers/researchers who can implement them with about the same level of success. The Netflix Challenge demonstrated that a massive, world-wide effort only improves on an in-house algorithm by approximately 10%. […] It’s relatively easy to build systems that are right <a href="http://www.cdixon.org/?p=342">80% of the time</a>, but very hard to go beyond that.</p>

<p>Algorithms are, as they say in business school, “commoditized.” The order of magnitude breakthroughs (and companies with real competitive advantages) are going to come from those who identify or create new data sources.</p>

<p>(That darned 80–20 rule should be promoted to a law.)</p>

<p>I’ve experienced this lately in working with my own startup and flirting with another. In both cases, the algorithms are intended to figure out what people find relevant or related. The algorithms aren’t that hard to write to achieve an 80% success rate. (In theory.) But they need to be <em>fed</em>.</p>

<p>The data that we require is largely public and already in existence at big companies — but collecting that data ourselves would be a long slog of unintelligent, undifferentiated work.</p>

<p>Luckily, those databases are available via APIs. (I don’t want to reveal the companies for fear of tipping off what we’re up to). Without those APIs, my company would be much harder to get off the ground.</p>

<p>So I take some comfort in knowing that my algorithm needs to be smart but not rocket science. And I feel lucky that these APIs exist.</p>

<p>But it does demonstrate one thing that can prevent small companies from usurping the big ones — data.</p>

</div>
<footer class="post-footer">
  

  <p id="find-me">
    <a href="https://mobile.twitter.com/clipperhouse">Find me at @clipperhouse</a>.
  </p>

</footer>
</article>

</main>

</body>
</html>

