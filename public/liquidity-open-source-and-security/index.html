<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Liquidity, open source and security · Matt Sherman</title>

	
	<meta name="author" content="Matt Sherman">

	
	<link href="/css/normalize.f4d7e8250f8f124f8b7d087e5e260766a34b079fddc43e7b20d8c18ca1e92e51.css" rel="stylesheet">

	
	<link href="/css/skeleton.fe835f755cb02ff20af143d9976ed3a50a1450caba26e1c0356b07fdbef2b4f9.css" rel="stylesheet">
	
	
	<link href="/css/style.3cc022a4ca3a2926be9d5150fe8ef92222d9445c74cd19385f4ff62d00a28468.css" rel="stylesheet">
	
	
	

	<link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png">
	<link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

</head>
<body>
	<header>
	<a href="https://clipperhouse.com">clipperhouse.com</a>
	<nav>
		<a href="/about/">about</a>
		<span class="sep">·</span>
		<a href="/jargon/">jargon</a>
		<span class="sep">·</span>
		<a href="/gen/overview/">gen</a>
		<span class="sep">·</span>
		<a href="/stack-correlations/">tag correlations</a>
	</nav>
</header>

	
	<main class="single">
		<article>
			<h1>Liquidity, open source and security</h1>
			<div>
				<p>Jeff has a <a href="http://blog.codinghorror.com/given-enough-money-all-bugs-are-shallow/">thoughtful post</a> about open source, security and incentives. A few points stood out to me.</p>
<h4 id="liquidity">Liquidity</h4>
<p>First, the “all bugs are shallow” idea is a bit idealistic, as he points out. What comes to mind for me is Joel’s <a href="http://www.joelonsoftware.com/articles/HighNotes.html">Hitting the High Notes</a>. Tens of thousands of average developers will not pick up a bug that only experts would recognize, and adding another ten thousand won’t help.</p>
<p>If we have a “chunky”, discrete Gaussian distribution of talent reviewing the code, the area under of the far right-hand tail may be indistinguishable from zero.</p>
<p>Few markets are liquid enough for distributions to be smooth, which allows <em>some</em> area under the right tail.</p>
<p>For example, casinos doing millions of bets with known probabilities have smooth, measurable, non-zero tails; they are liquid enough to predict that <em>someone</em> will win a million dollars.</p>
<p>An open source project with an audience <em>not</em> in the millions, less so. At some point moving right, the graph will <strong>discretely drop to zero</strong>. That zero represents “the number of people smart enough to identify difficult bugs”.</p>
<h4 id="incentives">Incentives</h4>
<p>Second, we consider incentives. Jeff explores the idea that paying for bugs may both be necessary and risky.</p>
<p>He sees moral hazard: perhaps there is an incentive to hoard important information for a payoff. Maybe only the wealthiest organizations can afford to pay for vulnerabilities, as their value is bid up.</p>
<p>But let’s consider the audience. A person that discovers a bug in an important piece of software is someone with an unusually strong interest in that software. They are likely a user, and therefore are more likely interested in having better software, for their own interests.</p>
<p>The alternative to imagine mercenaries that dive into unfamiliar software in the hope of a payoff. Not impossible! But unlikely.</p>
<p>Which is an essential quality of open source that confuses those new to it — that volunteers work not only on goodwill, but on self-interest.</p>
<p>I’ll stretch the analogy. The person next to you on the plane might be a terrorist. Not impossible!</p>
<p>But it’s more likely that, if they showed up where you showed up, they simply want the same things you do.</p>
<h4 id="cheaper">Cheaper</h4>
<p>What if security becomes too cheap to meter? Which is to say, what happens if improving software quality requires a lot fewer humans?</p>
<p>In that case, the economics and incentives questions become a lot less salient.</p>
<p>It’s possible — likely, to my mind — that safer software will not come mainly from greater resources, but better tools.</p>
<p>The two that come to mind are formal methods and safer languages. (These are actually two sides of the same coin.)</p>
<p>To the extent that we can formally articulate a definition for “safety”, we can prove a program’s characteristics with static analysis. Describing code paths in terms of provable propositions allows us to know where logical guarantees exist, and where they don’t.</p>
<p>We talk less about talent and trust, and more about the existence, or non-existence, of guarantees.</p>
<p>And heck, even informally: languages like Rust and Go prevent classes of human errors that C cannot. Using such languages, we prevent <em>the humans</em> from making certain classes of mistakes.</p>
<p>Both of the above strike me a relatively cheap and automatable, and therefore more likely a source of progress than foundations and funding.</p>

			</div>
		</article>
		<div class="post-meta">
			<p>—</p>
			<p>Published by Matt Sherman on April 4, 2015</p>
			<p>
				
					<a href="https://clipperhouse.com/improve-the-median-not-the-mean/" class="prev">← Improve the median, not the mean</a>
				
				
					<a href="https://clipperhouse.com/statements-are-statements-and-expressions-are-expressions-in-go/" class="next">Statements are statements, and expressions are expressions (in Go) →</a>
				
			</p>
		</div>
	</main>

	<footer>

</footer>

</body>

</html>
