<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Liquidity, open source and security
		</title>

	

	
	
			
			<link href="/css/normalize.580818700724d42d7fcc4979b0197971fca1c6d2e0286769237a0ac897df5512.css" rel="stylesheet">
		
			
			<link href="/css/style.2697af6c372ee608035f6cb6675ec4caaed1afb18b94a763db00113f4f6e78b4.css" rel="stylesheet">
		

	

	

	<link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png">
	<link rel="apple-touch-icon" href="/img/apple-touch-icon.png">
</head>
<body>
	<header>
	<nav>
		<a href="https://clipperhouse.com/">clipperhouse.com</a>
		<span class="sep">Â·</span>
		<a href="/jargon/">jargon</a>
		<span class="sep">Â·</span>
		<a href="/gen/overview/">gen</a>
		<span class="sep">Â·</span>
		<a href="/stack-correlations/">tag correlations</a>
		<span class="sep">Â·</span>
		<a href="/classical/">classical radio</a>
	</nav>
</header>

	
	<main class="single">
		<article>
			<h1>Liquidity, open source and security</h1>
			<div>
				<p>Jeff has a <a href="http://blog.codinghorror.com/given-enough-money-all-bugs-are-shallow/">thoughtful post</a> about open source, security and incentives. A few points stood out to me.</p>
<h3 id="liquidity">Liquidity</h3>
<p>First, the â€œall bugs are shallowâ€ idea is a bit idealistic, as he points out. What comes to mind for me is Joelâ€™s <a href="http://www.joelonsoftware.com/articles/HighNotes.html">Hitting the High Notes</a>. Tens of thousands of average developers will not pick up a bug that only experts would recognize, and adding another ten thousand wonâ€™t help.</p>
<p>If we have a â€œchunkyâ€, discrete Gaussian distribution of talent reviewing the code, the area under of the far right-hand tail may be indistinguishable from zero.</p>
<p>Few markets are liquid enough for distributions to be smooth, which allows <em>some</em> area under the right tail.</p>
<p>For example, casinos doing millions of bets with known probabilities have smooth, measurable, non-zero tails; they are liquid enough to predict that <em>someone</em> will win a million dollars.</p>
<p>An open source project with an audience <em>not</em> in the millions, less so. At some point moving right, the graph will <strong>discretely drop to zero</strong>. That zero represents â€œthe number of people smart enough to identify difficult bugsâ€.</p>
<h3 id="incentives">Incentives</h3>
<p>Second, we consider incentives. Jeff explores the idea that paying for bugs may both be necessary and risky.</p>
<p>He sees moral hazard: perhaps there is an incentive to hoard important information for a payoff. Maybe only the wealthiest organizations can afford to pay for vulnerabilities, as their value is bid up.</p>
<p>But letâ€™s consider the audience. A person that discovers a bug in an important piece of software is someone with an unusually strong interest in that software. They are likely a user, and therefore are more likely interested in having better software, for their own interests.</p>
<p>The alternative to imagine mercenaries that dive into unfamiliar software in the hope of a payoff. Not impossible! But unlikely.</p>
<p>Which is an essential quality of open source that confuses those new to itâ€Šâ€”â€Šthat volunteers work not only on goodwill, but on self-interest.</p>
<p>Iâ€™ll stretch the analogy. The person next to you on the plane might be a terrorist. Not impossible!</p>
<p>But itâ€™s more likely that, if they showed up where you showed up, they simply want the same things you do.</p>
<h3 id="cheaper">Cheaper</h3>
<p>What if security becomes too cheap to meter? Which is to say, what happens if improving software quality requires a lot fewer humans?</p>
<p>In that case, the economics and incentives questions become a lot less salient.</p>
<p>Itâ€™s possibleâ€Šâ€”â€Šlikely, to my mindâ€Šâ€”â€Šthat safer software will not come mainly from greater resources, but better tools.</p>
<p>The two that come to mind are formal methods and safer languages. (These are actually two sides of the same coin.)</p>
<p>To the extent that we can formally articulate a definition for â€œsafetyâ€, we can prove a programâ€™s characteristics with static analysis. Describing code paths in terms of provable propositions allows us to know where logical guarantees exist, and where they donâ€™t.</p>
<p>We talk less about talent and trust, and more about the existence, or non-existence, of guarantees.</p>
<p>And heck, even informally: languages like Rust and Go prevent classes of human errors that C cannot. Using such languages, we prevent <em>the humans</em> from making certain classes of mistakes.</p>
<p>Both of the above strike me a relatively cheap and automatable, and therefore more likely a source of progress than foundations and funding.</p>

			</div>
		</article>
		<div class="post-meta">
			<p>
				Published April 4, 2015</p>
			
		</div>
	</main>

	<footer>
    <p>
        <a href="/">Home</a>
        &nbsp;
        <a href="https://x.com/clipperhouse">ğ•</a>
        &nbsp;
        <a href="https://github.com/clipperhouse"> </a>
    </p>
</footer>

	
</body>
</html>
